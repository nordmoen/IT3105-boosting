\subsection{Glass Dataset}\label{glass dataset}
This dataset represents the classification of different glasses in a crime scene.

To run, use these options with the classifier options wanted.

\begin{lstlisting}[label=lst:glass, caption=Glass dataset general options]
--global 0.2 42 --file glass.txt --filter no.ntnu.ai.filter.GlassFilter
\end{lstlisting}


\begin{landscape}
\begin{table}
\begin{tabular}{|c|c|c||c|c|c||c||p{5cm}|}
\hline
NBC \# & Training Error & Standard Deviation & DTC \# & Training Error
& Standard Deviation & Test Error & Classifier option \\ \hline
1 & 0.339 & N/A & 0 & N/A & N/A & 18/43(41\%) & NBCGenerator 1 \\ \hline
0 & N/A & N/A & 1 & 0.181 & N/A & 17/43(39\%) & DTCGenerator 1 \\ \hline
5 & 0.391 & 0.045 & 0 & N/A & N/A & 19/43(44\%) & NBCGenerator 5 \\ \hline
10 & 0.371 & 0.042 & 0 & N/A & N/A & 19/43(44\%) & NBCGenerator 10 \\ \hline
20 & 0.358 & 0.034 & 0 & N/A & N/A & 20/43(46\%) & NBCGenerator 20 \\ \hline
0 & N/A & N/A & 5 & 0.256 & 0.043 & 18/43(41\%) & DTCGenerator 5 \\ \hline
0 & N/A & N/A & 10 & 0.673 & 0.133 & 23/43(53\%) & DTCGenerator 10 1 \\ \hline
0 & N/A & N/A & 10 & 0.623 & 0.124 & 24/43(55\%) & DTCGenerator 10 2 \\ \hline
0 & N/A & N/A & 10 & 0.265 & 0.047 & 18/43(41\%) & DTCGenerator 10 \\ \hline
0 & N/A & N/A & 20 & 0.268 & 0.042 & 19/43(44\%) & DTCGenerator 20 \\ \hline
5 & 0.430 & 0.046 & 5 & 0.651 & 0.095 & 21/43(48\%) & DTCGenerator 5 2, 
\newline NBCGenerator 5 \\ \hline
10 & 0.391 & 0.044 & 10 & 0.646 & 0.105 & 17/43(39\%) & DTCGenerator 10 2, 
\newline NBCGenerator 10 \\ \hline
20 & 0.409 & 0.045 & 20 & 0.661 & 0.093 & 22/43(51\%) & DTCGenerator 20 2, 
\newline NBCGenerator 20 \\ \hline
\hline
\end{tabular}
\label{tab:glass}
\caption[Glass dataset boosting]{Table showing the results of our classifiers 
on the Glass dataset}
\end{table}
\end{landscape}

This dataset was one of the harder ones given to us. The dataset was quite small
which made it hard to create a good classifier and the dataset it self was hard
to partition into buckets. From the description of the dataset at UCI we could
see that not all of the attributes was as important, but this fact is not
reflected in our classifiers. From the results above we can see that boosting
had very little to do with the result and it seems that the point at which we
split the dataset has the most significant importance. The variations between
Generators with more classifiers can be explained by the number of times we had
to throw away a classifier because it was to bad. This action introduces
randomness\footnote{Which is seeded so any attempts to recreate should see the
same result} which affected the results and explains why 20 classifiers for 
NBC can come up with a different result than 10 classifiers.
