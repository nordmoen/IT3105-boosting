\section{Results}\label{results}
Below is all the results from all our runs. We have used a couple standard
values to control the randomness and the split of the datasets.

For each run we have used a split of "0.2" which means that we use 0.2 of our
dataset as a test set. We have also used the random seed "42" for all runs
this means that in every place where we need a random number the generator for
that number is initialized in the same way with the same number each time. This
creates reproducibility and ensures that we can be certain that our results are
given the same starting point every time.

For each dataset we will point out what is needed to replicate the results.

The classifier options below does not conform to our actual command-line style
which is down to space requirement. To use just add the sentence '
--classifier no.ntnu.ai[nbc|dtc].' in front.

\input{glass.tex}

\input{pblocks.tex}

\input{yeast.tex}